{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of fine tuning on determinism\n",
    "\n",
    "In the V2 paper we found that determiniminsm was much higher for fine tuned models but they still were not perfect. Below is a partial recreation of the V2 experiment that we stopped because it was too expensive and we were getting the same results as before. \n",
    "\n",
    "We also have learned a great deal about how LLMs are operated and suspected that the fine tuning result was not due to the model being refined to the task but rather that fine tuned models cannot be run on other customer jobs leading to determinism due to actual equivalent inputs across runs. \n",
    "\n",
    "Below are partial results for experments we ran for v3.\n",
    "\n",
    "## Finetuning approach\n",
    "\n",
    "Running `python run_fine_tuned.py` will do the following:\n",
    "\n",
    "1. For each task in `TASKS = ['navigate', 'logical_deduction']`, if there is not a fine tuned model already created as indicated by the `model_map.csv`, ChatGPT3.5 is fine tuned with 2-fold cross validation on the first 100 rubrics with an even and odd folds. For each fold, e.g., even, the first 40 even numbered rubric are used to fine tune and the remaining 10 are used as a validation set for the fine tuner. \n",
    "\n",
    "2. For evaluation we attempted to run each task 10 times with the odd-finetuned model used to answer even questions and visa-versa. \n",
    "\n",
    "3. We ran out of funds on both runs so there are not 10 runs but the results are clear. Fine tuning increases TARr remarkably but it does not achieve determinism. \n",
    "\n",
    "Results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>model_config</th>\n",
       "      <th>task</th>\n",
       "      <th>task_config</th>\n",
       "      <th>TACr</th>\n",
       "      <th>TARr</th>\n",
       "      <th>TACa</th>\n",
       "      <th>TARa</th>\n",
       "      <th>correct_count_per_run</th>\n",
       "      <th>correct_pct_per_run</th>\n",
       "      <th>num_questions</th>\n",
       "      <th>N</th>\n",
       "      <th>best_possible_count</th>\n",
       "      <th>best_possible_accuracy</th>\n",
       "      <th>worst_possible_count</th>\n",
       "      <th>worst_possible_accuracy</th>\n",
       "      <th>spread</th>\n",
       "      <th>bootstrap_counts</th>\n",
       "      <th>bootstrap_pcts</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gpt-35_OAI</td>\n",
       "      <td>{'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BB4C5N1v', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BB4ImGvG'}</td>\n",
       "      <td>logical_deduction</td>\n",
       "      <td>{'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}</td>\n",
       "      <td>249</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>249</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>[111, 111, 110, 110, 110, 111, 110]</td>\n",
       "      <td>['44.4%', '44.4%', '44.0%', '44.0%', '44.0%', '44.4%', '44.0%']</td>\n",
       "      <td>250</td>\n",
       "      <td>7</td>\n",
       "      <td>111</td>\n",
       "      <td>44.4%</td>\n",
       "      <td>110</td>\n",
       "      <td>44.0%</td>\n",
       "      <td>0.4%</td>\n",
       "      <td>[110, 110, 110, 110, 110, 110, 110, 110, 111, 111]</td>\n",
       "      <td>['44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.4%', '44.4%']</td>\n",
       "      <td>2025-03-14_14-30-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gpt-35-turbo</td>\n",
       "      <td>{'temperature': 0.0, 'seed': 12, 'top_p_k': 0.0}</td>\n",
       "      <td>logical_deduction</td>\n",
       "      <td>{'prompt_type': 'v2', 'shots': 'few'}</td>\n",
       "      <td>199</td>\n",
       "      <td>79.6%</td>\n",
       "      <td>248</td>\n",
       "      <td>99.2%</td>\n",
       "      <td>[224, 224, 224, 225, 225, 223, 224, 223, 223, 223]</td>\n",
       "      <td>['89.6%', '89.6%', '89.6%', '90.0%', '90.0%', '89.2%', '89.6%', '89.2%', '89.2%', '89.2%']</td>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>225</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>223</td>\n",
       "      <td>89.2%</td>\n",
       "      <td>0.8%</td>\n",
       "      <td>[223, 223, 224, 224, 224, 224, 224, 224, 224, 225]</td>\n",
       "      <td>['89.2%', '89.2%', '89.6%', '89.6%', '89.6%', '89.6%', '89.6%', '89.6%', '89.6%', '90.0%']</td>\n",
       "      <td>2024-12-20_19-52-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gpt-35_OAI</td>\n",
       "      <td>{'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BAyYlUwJ', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BAymJYaT'}</td>\n",
       "      <td>navigate</td>\n",
       "      <td>{'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}</td>\n",
       "      <td>250</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>250</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>[163, 163, 163, 163, 163, 163]</td>\n",
       "      <td>['65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%']</td>\n",
       "      <td>250</td>\n",
       "      <td>6</td>\n",
       "      <td>163</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>163</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>[163, 163, 163, 163, 163, 163, 163, 163, 163, 163]</td>\n",
       "      <td>['65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%']</td>\n",
       "      <td>2025-03-14_09-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gpt-35-turbo</td>\n",
       "      <td>{'temperature': 0.0, 'seed': 12, 'top_p_k': 0.0}</td>\n",
       "      <td>navigate</td>\n",
       "      <td>{'prompt_type': 'v2', 'shots': 'few'}</td>\n",
       "      <td>217</td>\n",
       "      <td>86.8%</td>\n",
       "      <td>250</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>[240, 240, 240, 240, 240, 240, 240, 240, 240, 240]</td>\n",
       "      <td>['96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%']</td>\n",
       "      <td>250</td>\n",
       "      <td>10</td>\n",
       "      <td>240</td>\n",
       "      <td>96.0%</td>\n",
       "      <td>240</td>\n",
       "      <td>96.0%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>[240, 240, 240, 240, 240, 240, 240, 240, 240, 240]</td>\n",
       "      <td>['96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%']</td>\n",
       "      <td>2024-12-15_21-25-41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         model  \\\n",
       "0           0    gpt-35_OAI   \n",
       "2           2  gpt-35-turbo   \n",
       "1           1    gpt-35_OAI   \n",
       "3           3  gpt-35-turbo   \n",
       "\n",
       "                                                                                                                                                          model_config  \\\n",
       "0  {'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BB4C5N1v', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BB4ImGvG'}   \n",
       "2                                                                                                                     {'temperature': 0.0, 'seed': 12, 'top_p_k': 0.0}   \n",
       "1  {'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BAyYlUwJ', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BAymJYaT'}   \n",
       "3                                                                                                                     {'temperature': 0.0, 'seed': 12, 'top_p_k': 0.0}   \n",
       "\n",
       "                task  \\\n",
       "0  logical_deduction   \n",
       "2  logical_deduction   \n",
       "1           navigate   \n",
       "3           navigate   \n",
       "\n",
       "                                                 task_config  TACr    TARr  \\\n",
       "0  {'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}   249   99.6%   \n",
       "2                      {'prompt_type': 'v2', 'shots': 'few'}   199   79.6%   \n",
       "1  {'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}   250  100.0%   \n",
       "3                      {'prompt_type': 'v2', 'shots': 'few'}   217   86.8%   \n",
       "\n",
       "   TACa    TARa                               correct_count_per_run  \\\n",
       "0   249   99.6%                 [111, 111, 110, 110, 110, 111, 110]   \n",
       "2   248   99.2%  [224, 224, 224, 225, 225, 223, 224, 223, 223, 223]   \n",
       "1   250  100.0%                      [163, 163, 163, 163, 163, 163]   \n",
       "3   250  100.0%  [240, 240, 240, 240, 240, 240, 240, 240, 240, 240]   \n",
       "\n",
       "                                                                          correct_pct_per_run  \\\n",
       "0                             ['44.4%', '44.4%', '44.0%', '44.0%', '44.0%', '44.4%', '44.0%']   \n",
       "2  ['89.6%', '89.6%', '89.6%', '90.0%', '90.0%', '89.2%', '89.6%', '89.2%', '89.2%', '89.2%']   \n",
       "1                                      ['65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%']   \n",
       "3  ['96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%']   \n",
       "\n",
       "   num_questions   N  best_possible_count best_possible_accuracy  \\\n",
       "0            250   7                  111                  44.4%   \n",
       "2            250  10                  225                  90.0%   \n",
       "1            250   6                  163                  65.2%   \n",
       "3            250  10                  240                  96.0%   \n",
       "\n",
       "   worst_possible_count worst_possible_accuracy spread  \\\n",
       "0                   110                   44.0%   0.4%   \n",
       "2                   223                   89.2%   0.8%   \n",
       "1                   163                   65.2%   0.0%   \n",
       "3                   240                   96.0%   0.0%   \n",
       "\n",
       "                                     bootstrap_counts  \\\n",
       "0  [110, 110, 110, 110, 110, 110, 110, 110, 111, 111]   \n",
       "2  [223, 223, 224, 224, 224, 224, 224, 224, 224, 225]   \n",
       "1  [163, 163, 163, 163, 163, 163, 163, 163, 163, 163]   \n",
       "3  [240, 240, 240, 240, 240, 240, 240, 240, 240, 240]   \n",
       "\n",
       "                                                                               bootstrap_pcts  \\\n",
       "0  ['44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.0%', '44.4%', '44.4%']   \n",
       "2  ['89.2%', '89.2%', '89.6%', '89.6%', '89.6%', '89.6%', '89.6%', '89.6%', '89.6%', '90.0%']   \n",
       "1  ['65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%']   \n",
       "3  ['96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%', '96.0%']   \n",
       "\n",
       "                  date  \n",
       "0  2025-03-14_14-30-21  \n",
       "2  2024-12-20_19-52-06  \n",
       "1  2025-03-14_09-09-18  \n",
       "3  2024-12-15_21-25-41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 250 #(default is 20)\n",
    "pd.options.display.max_rows = 250 #(default is 60)\n",
    "pd.options.display.max_colwidth = 250 #(default is 50)\n",
    "\n",
    "# stability_eval.csv created by running `python ../../evaluate.py runs/`\n",
    "df = pd.read_csv('stability_eval.csv')\n",
    "display(df.sort_values(by='task'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gpt-35_OAI` models are the fine tuned ones and there is actual determinism for `navigate` and near determinism for `logical_deducation`. There is a considerable drop in performance for the fine tuned models so there may be issuess with the implementation--this is not expected. In the V2 experiments, the fine tuned models did not show such degredation (they were not fine-tuned the same way) but we did see the increase in determinism. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are we seeing determinsm due to being only data being processed?\n",
    "\n",
    "It is possible that we got increased determinism just by being the only job on the LLM? \n",
    "To test this we ran logical deduction on the navigation fine tuned model and visa versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>model_config</th>\n",
       "      <th>task</th>\n",
       "      <th>task_config</th>\n",
       "      <th>TACr</th>\n",
       "      <th>TARr</th>\n",
       "      <th>TACa</th>\n",
       "      <th>TARa</th>\n",
       "      <th>correct_count_per_run</th>\n",
       "      <th>correct_pct_per_run</th>\n",
       "      <th>num_questions</th>\n",
       "      <th>N</th>\n",
       "      <th>best_possible_count</th>\n",
       "      <th>best_possible_accuracy</th>\n",
       "      <th>worst_possible_count</th>\n",
       "      <th>worst_possible_accuracy</th>\n",
       "      <th>spread</th>\n",
       "      <th>bootstrap_counts</th>\n",
       "      <th>bootstrap_pcts</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gpt-35_OAI</td>\n",
       "      <td>{'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BAyYlUwJ', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BAymJYaT'}</td>\n",
       "      <td>logical_deduction</td>\n",
       "      <td>{'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}</td>\n",
       "      <td>249</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>249</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>[118, 118, 118, 117]</td>\n",
       "      <td>['47.2%', '47.2%', '47.2%', '46.8%']</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>47.2%</td>\n",
       "      <td>117</td>\n",
       "      <td>46.8%</td>\n",
       "      <td>0.4%</td>\n",
       "      <td>[117, 117, 117, 118, 118, 118, 118, 118, 118, 118]</td>\n",
       "      <td>['46.8%', '46.8%', '46.8%', '47.2%', '47.2%', '47.2%', '47.2%', '47.2%', '47.2%', '47.2%']</td>\n",
       "      <td>2025-03-15_20-37-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gpt-35_OAI</td>\n",
       "      <td>{'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BB4C5N1v', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BB4ImGvG'}</td>\n",
       "      <td>navigate</td>\n",
       "      <td>{'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}</td>\n",
       "      <td>249</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>249</td>\n",
       "      <td>99.6%</td>\n",
       "      <td>[162, 163, 163, 163, 163]</td>\n",
       "      <td>['64.8%', '65.2%', '65.2%', '65.2%', '65.2%']</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "      <td>65.2%</td>\n",
       "      <td>162</td>\n",
       "      <td>64.8%</td>\n",
       "      <td>0.4%</td>\n",
       "      <td>[163, 163, 163, 163, 163, 163, 163, 163, 163, 163]</td>\n",
       "      <td>['65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%']</td>\n",
       "      <td>2025-03-15_19-58-38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       model  \\\n",
       "1           1  gpt-35_OAI   \n",
       "0           0  gpt-35_OAI   \n",
       "\n",
       "                                                                                                                                                          model_config  \\\n",
       "1  {'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BAyYlUwJ', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BAymJYaT'}   \n",
       "0  {'temperature': 0.0, 'seed': 12, 'top_p_k': 1.0, 'even_model': 'ft:gpt-3.5-turbo-0125:personal::BB4C5N1v', 'odd_model': 'ft:gpt-3.5-turbo-0125:personal::BB4ImGvG'}   \n",
       "\n",
       "                task  \\\n",
       "1  logical_deduction   \n",
       "0           navigate   \n",
       "\n",
       "                                                 task_config  TACr   TARr  \\\n",
       "1  {'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}   249  99.6%   \n",
       "0  {'prompt_type': 'v2', 'shots': 'few', 'fine_tuned': True}   249  99.6%   \n",
       "\n",
       "   TACa   TARa      correct_count_per_run  \\\n",
       "1   249  99.6%       [118, 118, 118, 117]   \n",
       "0   249  99.6%  [162, 163, 163, 163, 163]   \n",
       "\n",
       "                             correct_pct_per_run  num_questions  N  \\\n",
       "1           ['47.2%', '47.2%', '47.2%', '46.8%']            250  4   \n",
       "0  ['64.8%', '65.2%', '65.2%', '65.2%', '65.2%']            250  5   \n",
       "\n",
       "   best_possible_count best_possible_accuracy  worst_possible_count  \\\n",
       "1                  118                  47.2%                   117   \n",
       "0                  163                  65.2%                   162   \n",
       "\n",
       "  worst_possible_accuracy spread  \\\n",
       "1                   46.8%   0.4%   \n",
       "0                   64.8%   0.4%   \n",
       "\n",
       "                                     bootstrap_counts  \\\n",
       "1  [117, 117, 117, 118, 118, 118, 118, 118, 118, 118]   \n",
       "0  [163, 163, 163, 163, 163, 163, 163, 163, 163, 163]   \n",
       "\n",
       "                                                                               bootstrap_pcts  \\\n",
       "1  ['46.8%', '46.8%', '46.8%', '47.2%', '47.2%', '47.2%', '47.2%', '47.2%', '47.2%', '47.2%']   \n",
       "0  ['65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%', '65.2%']   \n",
       "\n",
       "                  date  \n",
       "1  2025-03-15_20-37-46  \n",
       "0  2025-03-15_19-58-38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 250 #(default is 20)\n",
    "pd.options.display.max_rows = 250 #(default is 60)\n",
    "pd.options.display.max_colwidth = 250 #(default is 50)\n",
    "\n",
    "# stability_eval_cross_trained.csv created by running `python ../../evaluate.py cross_trained/`\n",
    "# and then `mv stability_eval.csv stability_eval_cross_trained.csv`\n",
    "df = pd.read_csv('stability_eval_cross_trained.csv')\n",
    "display(df.sort_values(by='task'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see nearly the same level of determinsm so the hypothesis that fine tuning helps determinism looks more likely to be due to being only job on the LLM given that a poorly trained LLM is equally deterministic. But the non-drop in accuracy indicates that there may be bugs/problems with the approach. Out of time/resources so not pursuing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3rd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
